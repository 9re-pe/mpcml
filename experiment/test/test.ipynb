{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e61abc32-8627-4f87-83f4-fbac70145760",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "root_dir = '../../'\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from modules import losses, models, samplers, regularizers, evaluators, trainers, datasets, distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a41011c-dafb-451f-9f86-9954ad74054d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get data\n",
    "# dataset = datasets.ML100k()\n",
    "dataset = datasets.ML20m()\n",
    "n_user = dataset.n_user\n",
    "n_item = dataset.n_item\n",
    "train_set, test_set = dataset.get_train_and_test_set(use_negative_sampling=True)\n",
    "\n",
    "# device setting\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_set = torch.LongTensor(train_set).to(device)\n",
    "test_set = torch.LongTensor(test_set).to(device)\n",
    "#item_feature_set = torch.LongTensor(item_feature_set).to(device)\n",
    "\n",
    "# set hyperparameters\n",
    "lr = 1e-3\n",
    "n_dim = 50\n",
    "\n",
    "# set model\n",
    "#distribution = distributions.Empirical()\n",
    "#distribution = distributions.Gaussian()\n",
    "#distribution = distributions.Gamma()\n",
    "model = models.CollaborativeMetricLearning(n_user, n_item, n_dim).to(device)\n",
    "#model = models.MutualProximityCML(n_user, n_item, distribution, n_dim).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = losses.SumTripletLoss(margin=1).to(device)\n",
    "sampler = samplers.BaseSampler(train_set, n_user, n_item, device=device, strict_negative=False)\n",
    "\n",
    "# set evaluator\n",
    "ks=[10, 50]\n",
    "evaluator = evaluators.RecallEvaluator(test_set, ks)\n",
    "#evaluator = evaluators.CoverageEvaluator(test_set, ks)\n",
    "#evaluator = evaluators.DiversityEvaluator(test_set, item_feature_set, ks, emb_sim=False)\n",
    "#evaluator = evaluators.HubnessEvaluator(test_set, ks)\n",
    "#evaluator = evaluators.UnpopularityEvaluator(test_set, ks)\n",
    "#evaluator = evaluators.F1ScoreEvaluator(test_set, ks)\n",
    "trainer = trainers.BaseTrainer(model, optimizer, criterion, sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e93c98f7-e1c2-4f22-967c-cb51e1cc2769",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████████▏                                            | 31527/138287 [00:57<03:15, 546.64it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_evaluator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/OneDrive/Documents/project/lab/bachelor/cml_pytorch2/experiment/test/../../modules/trainers/BaseTrainer.py:54\u001b[0m, in \u001b[0;36mBaseTrainer.fit\u001b[0;34m(self, n_batch, n_epoch, valid_evaluator, valid_per_epoch)\u001b[0m\n\u001b[1;32m     52\u001b[0m valid_or_not \u001b[38;5;241m=\u001b[39m valid_evaluator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid_or_not:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_scores \u001b[38;5;241m=\u001b[39m \u001b[43mvalid_evaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_scores[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_scores[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlosses\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n",
      "File \u001b[0;32m~/OneDrive/Documents/project/lab/bachelor/cml_pytorch2/experiment/test/../../modules/evaluators/RecallEvaluator.py:112\u001b[0m, in \u001b[0;36mRecallEvaluator.score\u001b[0;34m(self, model, reduction, verbose)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m uid \u001b[38;5;129;01min\u001b[39;00m tqdm(users):\n\u001b[0;32m--> 112\u001b[0m         df_eval_sub \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_user\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m         df_eval \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_eval, df_eval_sub])\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/OneDrive/Documents/project/lab/bachelor/cml_pytorch2/experiment/test/../../modules/evaluators/RecallEvaluator.py:76\u001b[0m, in \u001b[0;36mRecallEvaluator.eval_user\u001b[0;34m(self, model, uid)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# test_setから対象ユーザ(uid)の行をすべて取り出す(user_idとitem_idの列のみ)\u001b[39;00m\n\u001b[1;32m     75\u001b[0m user_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_set[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m uid\n\u001b[0;32m---> 76\u001b[0m test_set_pair \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_set\u001b[49m\u001b[43m[\u001b[49m\u001b[43muser_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# y_hat_user, y_test_userにはそれぞれ予測値と真値が[0, 1, 0, ..., 0]というような形で格納される必要がある\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# y_hat_user, y_test_userのサイズは一緒で、どのアイテムに対する評価か、という順番は対応している必要がある\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# y_hat_user, y_test_userのサイズはユーザごとに変わってくる(trainに含まれる分が違うため)\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# distance for each user and item pair size (n_pairs)\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# test_set_pairに対する結果の予測を行う(proximityを返す)\u001b[39;00m\n\u001b[1;32m     84\u001b[0m y_hat_user \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_set_pair)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.fit(n_batch=256, n_epoch=20, valid_evaluator = evaluator, valid_per_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae210ed-25fe-4e9e-aa1a-059b00626ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.valid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae8e683-24bc-49c5-a0fd-e333d45bb50d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e039426a-f8c3-45a7-944c-67258226f149",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelor2",
   "language": "python",
   "name": "bachelor2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
